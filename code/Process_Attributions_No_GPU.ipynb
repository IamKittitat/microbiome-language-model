{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Takes the per-sample prediction scores and the per-taxa attribution values (both from Attribution_calculations.ipynb) and identifies the taxa most and least associated with IBD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szzXt90f_0Ay",
        "outputId": "04ba8ce5-008d-4098-9aa6-6c6c15a0ab92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "device = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XL_WgAdLacBd"
      },
      "outputs": [],
      "source": [
        "def load_dict_from_at_tensor(at_tensor):\n",
        "    \"\"\"\n",
        "    Loads a dictionary of attributions from a tensor.\n",
        "    \"\"\"\n",
        "    attributions = {}\n",
        "    for i in range(len(at_tensor)):\n",
        "        sample = int(at_tensor[i][0].item())\n",
        "        microbe = int(at_tensor[i][1].item())\n",
        "        att = at_tensor[i][2].item()\n",
        "        base = at_tensor[i][3].item()\n",
        "        if not microbe in attributions:\n",
        "            attributions[microbe] = [[], [], []]\n",
        "        attributions[microbe][0].append(base)\n",
        "        attributions[microbe][1].append(att)\n",
        "        attributions[microbe][2].append(sample)\n",
        "    return attributions\n",
        "\n",
        "# Load the different attribution values we calculated from the Attribution_calculations.ipynb\n",
        "sh_at_tensor = torch.load('/path/to/Schirmer_attributions_e.pth')\n",
        "sh_attributions = load_dict_from_at_tensor(sh_at_tensor)\n",
        "\n",
        "hf_at_tensor = torch.load(\"/path/to/Halfvarson_attributions_e.pth\")\n",
        "hf_attributions = load_dict_from_at_tensor(hf_at_tensor)\n",
        "\n",
        "ibd_at_tensor = torch.load('/path/to/IBD_attributions_e.pth')\n",
        "ibd_attributions = load_dict_from_at_tensor(ibd_at_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf3KO7Zjke3c",
        "outputId": "c5510315-9f25-4186-9d69-9380635a6beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(510, dtype=torch.int32) 564\n",
            "tensor(155, dtype=torch.int32) 197\n",
            "tensor(435) 8571\n"
          ]
        }
      ],
      "source": [
        "# Load the labels for the different datasets\n",
        "hvl = torch.from_numpy(np.load(\"/path/to/halfvarson_IBD_labels.npy\"))\n",
        "sl = torch.from_numpy(np.load(\"/path/to/schirmer_IBD_labels.npy\"))\n",
        "ibdl = torch.from_numpy(np.load(\"/path/to/total_IBD_label.npy\")[:,0])\n",
        "print(sum(hvl), len(hvl))\n",
        "print(sum(sl), len(sl))\n",
        "print(sum(ibdl), len(ibdl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1Ftp3Xa4hAie"
      },
      "outputs": [],
      "source": [
        "# Load the different datasets\n",
        "hvd = np.load(\"/path/to/halfvarson_512_otu.npy\")\n",
        "sd = np.load(\"/path/to/schirmer_IBD_512_otu.npy\")\n",
        "ibdd = np.load(\"/path/to/total_IBD_512.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W77RCLojToo1"
      },
      "outputs": [],
      "source": [
        "# Load the base scores for the different datasets (as calculated in Attribution_calculations.ipynb)\n",
        "ibd_base_scores = torch.load('/path/to/IBD_base_scores_e.pth')[0]\n",
        "hf_base_scores = torch.load('/path/to/Halfvarson_base_scores_e.pth')[0]\n",
        "sh_base_scores = torch.load('/path/to/Schirmer_base_scores_e.pth')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ybgG2E2_p3PY"
      },
      "outputs": [],
      "source": [
        "def filter_attributions_and_plot_hbars(attribution_dict, lenlim=10, title=\"Unspecified\",\n",
        "                                       neg_cutoff=1, pos_cutoff=0, per_microbe_std=True, n=30,\n",
        "                                       data_labels=None, filter=False, rarity_lim=0, total_freqs=[],\n",
        "                                       all_scores=[], sort_by_positive_class_attribution=False, plot=True):\n",
        "    \"\"\"\n",
        "    Filter and analyze attribution data for microbes, optionally plotting the results.\n",
        "\n",
        "    This function processes attribution data for microbes, applying various filters and\n",
        "    calculating statistics. It can optionally generate a horizontal bar plot of the results.\n",
        "\n",
        "    Parameters:\n",
        "    - attribution_dict (dict): Dictionary containing attribution data for each microbe.\n",
        "    - lenlim (int): Minimum number of attributions required for a microbe to be included.\n",
        "    - title (str): Title for the plot.\n",
        "    - neg_cutoff (float): Cutoff percentile for negative-class scores. For a datapoint with a negative label, its score must be below or equal to the provided percentile.\n",
        "    - pos_cutoff (float): Cutoff percentile for positive-class scores. For a datapoint with a positive label, its score must be above or equal to the provided percentile.\n",
        "    - per_microbe_std (bool): If True, use per-microbe standard deviation for the standard deviation of the attribution scores for plotting error bars; otherwise, use sample size adjusted std.\n",
        "    - n (int): Number of top microbes to analyze and potentially plot.\n",
        "    - data_labels (array-like): Binary true labels for the samples.\n",
        "    - filter (bool): If True, apply filtering based on scores and rarity.\n",
        "    - rarity_lim (int): Minimum frequency of occurrence for a microbe to be included.\n",
        "    - total_freqs (list): List of total occurrence frequencies for each microbe.\n",
        "    - all_scores (list): List of all attribution scores (from Attribution_calculations.ipynb).\n",
        "    - sort_by_positive_class_attribution (bool): If True, sort by attributions on the positive class alone; otherwise, sort by overall attribution.\n",
        "    - plot (bool): If True, generate and display a plot of the results.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: (microbes, microbe_stats, filtered_attribution_dict)\n",
        "        microbes (list): List of top microbe IDs.\n",
        "        microbe_stats (list): Statistics for each microbe (microbe_id, num_attributions, sum_attributions, std_attributions, index).\n",
        "        filtered_attribution_dict (dict): Filtered attribution dictionary.\n",
        "\n",
        "    The function performs the following steps:\n",
        "    1. Optionally filters the attribution data based on scores and rarity.\n",
        "    2. Calculates statistics for positive and negative attributions.\n",
        "    3. Sorts the results based on specified criteria.\n",
        "    4. Returns the top n microbes, their statistics, and the filtered attribution dictionary.\n",
        "    5. Optionally generates a horizontal bar plot of the top microbes' attributions.\n",
        "\n",
        "    The plot, if generated, shows positive and negative attributions for each microbe,\n",
        "    along with error bars and additional annotations about sample counts and attribution types.\n",
        "    \"\"\"    \n",
        "    \n",
        "    if filter:\n",
        "        sorted_neg_scores = sorted(all_scores[(1 - data_labels).to(torch.bool)])\n",
        "        sorted_pos_scores = sorted(all_scores[data_labels.to(torch.bool)])\n",
        "\n",
        "        # Calculate cutoff scores for negative and positive classes\n",
        "        neg_cutoff_score = sorted_neg_scores[int(neg_cutoff * len(sorted_neg_scores))]\n",
        "        pos_cutoff_score = sorted_pos_scores[min(int(pos_cutoff * len(sorted_pos_scores)), len(sorted_pos_scores) - 1)]\n",
        "        \n",
        "        # Apply filtering to the attribution dictionary\n",
        "        attribution_dict = copy.deepcopy(attribution_dict)\n",
        "        for k in attribution_dict.keys():\n",
        "            entry = attribution_dict[k]\n",
        "            filtered_results = [[entry[0][i], entry[1][i], entry[2][i]] for i in range(len(entry[0])) if ( \\\n",
        "                                                                ((not data_labels[entry[2][i]]) and entry[0][i] <= neg_cutoff_score or \\\n",
        "                                                                 data_labels[entry[2][i]] and entry[0][i] >= pos_cutoff_score) and \\\n",
        "                                                                (entry[2][i] in total_freqs and total_freqs[entry[2][i]] >= rarity_lim))]\n",
        "            # Update the filtered results in the attribution dictionary\n",
        "            entry[0] = [e[0] for e in filtered_results]\n",
        "            entry[1] = [e[1] for e in filtered_results]\n",
        "            entry[2] = [e[2] for e in filtered_results]\n",
        "    # Create a list of attribution results for each microbe meeting the criteria:\n",
        "    # Each sublist contains: [microbe_id, num_attributions, sum_attributions, std_attributions, \n",
        "    #                         sum_abs_attributions, std_abs_attributions]\n",
        "    # Only includes microbes with at least 'lenlim' attributions and excludes microbe ID 26727\n",
        "    attribution_results = [\n",
        "        [\n",
        "            k, #0 Microbe ID\n",
        "            len(attribution_dict[k][1]), #1 Number of attributions\n",
        "            sum(attribution_dict[k][1]), #2 Sum of attributions\n",
        "            np.std(attribution_dict[k][1]), #3 Standard deviation of attributions\n",
        "            sum([abs(w) for w in attribution_dict[k][1]]), #4 Sum of absolute values of all attributions\n",
        "            np.std([abs(w) for w in attribution_dict[k][1]]) #5 Standard deviation of absolute values of all attributions\n",
        "        ] \n",
        "        for k in attribution_dict.keys() \n",
        "        if (len(attribution_dict[k][1]) >= lenlim and k != 26727)\n",
        "    ]\n",
        "    attribution_results = sorted(attribution_results, reverse=True, key=lambda x : x[2] / x[1])\n",
        "\n",
        "    # Separate positive and negative attributions\n",
        "    positive_attribution_dict = copy.deepcopy(attribution_dict)\n",
        "    for k in positive_attribution_dict.keys():\n",
        "        positive_attribution_dict[k][1] = [at for at in positive_attribution_dict[k][1] if at > 0]\n",
        "    negative_attribution_dict = copy.deepcopy(attribution_dict)\n",
        "    for k in positive_attribution_dict.keys():\n",
        "        negative_attribution_dict[k][1] = [at for at in negative_attribution_dict[k][1] if at < 0]\n",
        "\n",
        "    # Calculate detailed statistics for positive attributions\n",
        "    positive_attribution_results = [\n",
        "        [\n",
        "            k,  #0 Microbe ID\n",
        "            len(positive_attribution_dict[k][1]),  #1 Number of positive attributions\n",
        "            sum(positive_attribution_dict[k][1]),  #2 Sum of positive attributions\n",
        "            np.std(positive_attribution_dict[k][1]) if len(positive_attribution_dict[k][1]) > 0 else 0,  #3 Standard deviation of positive attributions (0 if none)\n",
        "            sum([abs(w) for w in attribution_dict[k][1]]),  #4 Sum of absolute values of all attributions\n",
        "            np.std([abs(w) for w in attribution_dict[k][1]]) if len(positive_attribution_dict[k][1]) > 0 else 0,  #5 Standard deviation of absolute attributions (0 if no positive attributions)\n",
        "            len(attribution_dict[k][1]),  #6 Total number of attributions (positive and negative)\n",
        "            sum(attribution_dict[k][1])  #7 Sum of all attributions (positive and negative)\n",
        "        ]\n",
        "        for k in attribution_dict.keys()\n",
        "        if (len(attribution_dict[k][1]) >= lenlim and k != 26727)  # Include only if total attributions >= lenlim and microbe ID is not 26727\n",
        "    ]\n",
        "\n",
        "    # Calculate detailed statistics for negative attributions\n",
        "    negative_attribution_results = [\n",
        "        [\n",
        "            k,  #0 Microbe ID\n",
        "            len(negative_attribution_dict[k][1]),  #1 Number of negative attributions\n",
        "            sum(negative_attribution_dict[k][1]),  #2 Sum of negative attributions\n",
        "            np.std(negative_attribution_dict[k][1]) if len(negative_attribution_dict[k][1]) > 0 else 0,  #3 Standard deviation of negative attributions (0 if none)\n",
        "            sum([abs(w) for w in attribution_dict[k][1]]),  #4 Sum of absolute values of all attributions\n",
        "            np.std([abs(w) for w in attribution_dict[k][1]]) if len(negative_attribution_dict[k][1]) > 0 else 0,  #5 Standard deviation of absolute attributions (0 if no negative attributions)\n",
        "            len(attribution_dict[k][1]),  #6 Total number of attributions (positive and negative)\n",
        "            len(positive_attribution_dict[k][1]),  #7 Number of positive attributions\n",
        "            sum(positive_attribution_dict[k][1]),  #8 Sum of positive attributions\n",
        "            sum(attribution_dict[k][1])  #9 Sum of all attributions (positive and negative)\n",
        "        ]\n",
        "        for k in attribution_dict.keys()\n",
        "        if (len(attribution_dict[k][1]) >= lenlim and k != 26727)  # Include only if total attributions >= lenlim and microbe ID is not 26727\n",
        "    ]\n",
        "\n",
        "    # Sort attribution results based on specified criteria (either by average positive class attribution or by average total attribution)\n",
        "    if sort_by_positive_class_attribution:\n",
        "        positive_attribution_results = sorted(positive_attribution_results, reverse=True, key=lambda x : x[2] / max(x[1], 1))\n",
        "        negative_attribution_results = sorted(negative_attribution_results, reverse=True, key=lambda x : x[8] / max(x[7], 1))\n",
        "    else:\n",
        "        positive_attribution_results = sorted(positive_attribution_results, reverse=True, key=lambda x : x[7] / x[6])\n",
        "        negative_attribution_results = sorted(negative_attribution_results, reverse=True, key=lambda x : x[9] / x[6])\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    microbes = [j[0] for j in attribution_results[:n]]\n",
        "    positive_attributions = [j[2] / max(j[1], 1) for j in positive_attribution_results[:n]]\n",
        "    negative_attributions = [j[2] / max(j[1], 1) for j in negative_attribution_results[:n]]\n",
        "\n",
        "    frequencies = [[j[0], j[1]] for j in attribution_results[:n]]\n",
        "    positive_errors = [j[3] / (1 if per_microbe_std else np.sqrt(max(j[1], 1))) for j in positive_attribution_results[:n]]\n",
        "    negative_errors = [j[3] / (1 if per_microbe_std else np.sqrt(max(j[1], 1))) for j in negative_attribution_results[:n]]\n",
        "    \n",
        "    # microbe_stats entry: [microbe_id, num_attributions, sum_attributions, std_attributions, index]\n",
        "    microbe_stats = [[j[0], j[1], j[2], j[3], l] for j,l in zip(attribution_results, range(len(attribution_results)))]\n",
        "    if plot:\n",
        "        plt.barh(range(n), positive_attributions, label=\"Positive\", xerr=positive_errors)\n",
        "        plt.barh(range(n), negative_attributions, label=\"Negative\", xerr=negative_errors)\n",
        "        plt.title(\"Positive and Negative Attribution Results For \" + title)\n",
        "        plt.legend()\n",
        "        xlim = -1000\n",
        "        for i, v in enumerate(frequencies):\n",
        "            if data_labels is None:\n",
        "                annotation = str(v[1])\n",
        "            else:\n",
        "                samples = np.array(attribution_dict[v[0]][2])\n",
        "                n_pos = sum(data_labels[samples]).item()\n",
        "                annotation = \"P:\" + str(n_pos) + \",  N:\" + str(v[1] - n_pos) + \"  --  PA:\" + str(positive_attribution_results[i][1]) + \", NA:\" + str(negative_attribution_results[i][1])\n",
        "            text_x_loc = positive_attributions[i] + positive_errors[i] + 0.02 * (sum(positive_attributions) - sum(negative_attributions)) / n\n",
        "            plt.text(text_x_loc, i - 0.15, annotation)\n",
        "            if text_x_loc > xlim:\n",
        "                xlim = text_x_loc\n",
        "        xlim += 0.35 * (sum(positive_attributions) - sum(negative_attributions)) / n\n",
        "        plt.xlim((-xlim, xlim))\n",
        "        plt.yticks(range(n), microbes)\n",
        "        plt.ylabel(\"Microbe ID\")\n",
        "        plt.xlabel(\"Attribution (Feature Ablation)\")\n",
        "        plt.show()\n",
        "    return microbes, microbe_stats, attribution_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tcgKdVy5M9lz"
      },
      "outputs": [],
      "source": [
        "# Count the total number of attributions for each microbe across all datasets\n",
        "counts_dict = {}\n",
        "for ad in [hf_attributions, ibd_attributions, sh_attributions]:\n",
        "    for m in ad.keys():\n",
        "        if not m in counts_dict:\n",
        "            counts_dict[m] = 0\n",
        "        counts_dict[m] += len(ad[m][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPAziGbxFYXd",
        "outputId": "8b45b2cd-f93c-4730-d1a9-658b12446c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L = 5, n = 300\n"
          ]
        }
      ],
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# Set cutoff values for positive and negative class scores\n",
        "pos_cf = 0.5\n",
        "neg_cf = 0.5\n",
        "# Set rarity limit to 5% of the total sample size\n",
        "rarity_l = int(9332 * 0.05)\n",
        "\n",
        "# Set minimum number of attributions required for a microbe to be included\n",
        "L = 5\n",
        "print(\"L = 5, n = 30000\")\n",
        "\n",
        "# Process Halfvarson dataset attributions\n",
        "top_half_abs_L_5_n_300, top_half_abs_L_5_n_300_stats, filtered_hf_atts = filter_attributions_and_plot_hbars(\n",
        "    hf_attributions,  # Halfvarson attributions\n",
        "    n=30000,  # Number of top microbes to analyze\n",
        "    sort_by_positive_class_attribution=False,\n",
        "    pos_cutoff=pos_cf,\n",
        "    neg_cutoff=neg_cf,\n",
        "    lenlim=L,  # Minimum number of attributions\n",
        "    rarity_lim=rarity_l,\n",
        "    absolute=False,\n",
        "    title=\"Halfvarson (Per Sample STD)\",\n",
        "    data_labels=hvl,  # Halfvarson labels\n",
        "    filter=True,\n",
        "    all_scores=hf_base_scores,\n",
        "    total_freqs=counts_dict,\n",
        "    plot=False  # Don't generate plot\n",
        ")\n",
        "\n",
        "# Process IBD dataset attributions\n",
        "top_ibd_abs_L_5_n_300, top_ibd_abs_L_5_n_300_stats, filtered_ibd_atts = filter_attributions_and_plot_hbars(\n",
        "    ibd_attributions,  # IBD attributions\n",
        "    n=30000,\n",
        "    sort_by_positive_class_attribution=False,\n",
        "    pos_cutoff=pos_cf,\n",
        "    neg_cutoff=neg_cf,\n",
        "    lenlim=L,\n",
        "    rarity_lim=rarity_l,\n",
        "    absolute=False,\n",
        "    title=\"IBD (Per Sample STD)\",\n",
        "    data_labels=ibdl,  # IBD labels\n",
        "    filter=True,\n",
        "    all_scores=ibd_base_scores,\n",
        "    total_freqs=counts_dict,\n",
        "    plot=False\n",
        ")\n",
        "\n",
        "# Process Schirmer dataset attributions\n",
        "top_sh_abs_L_5_n_300, top_sh_abs_L_5_n_300_stats, filtered_sh_atts = filter_attributions_and_plot_hbars(\n",
        "    sh_attributions,  # Schirmer attributions\n",
        "    n=30000,\n",
        "    sort_by_positive_class_attribution=False,\n",
        "    pos_cutoff=pos_cf,\n",
        "    neg_cutoff=neg_cf,\n",
        "    lenlim=L,\n",
        "    rarity_lim=rarity_l,\n",
        "    absolute=False,\n",
        "    title=\"Schirmer (Per Sample STD)\",\n",
        "    data_labels=sl,  # Schirmer labels\n",
        "    filter=True,\n",
        "    all_scores=sh_base_scores,\n",
        "    total_freqs=counts_dict,\n",
        "    plot=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Pp5wGhjYxLg7"
      },
      "outputs": [],
      "source": [
        "# Combine Halfvarson and Schirmer attributions\n",
        "hf_sh_attributions = copy.deepcopy(hf_attributions)\n",
        "sh_attributions_c = copy.deepcopy(sh_attributions)\n",
        "\n",
        "# Merge Schirmer attributions into the combined dictionary\n",
        "for m in sh_attributions_c.keys():\n",
        "    if not m in hf_sh_attributions:\n",
        "        hf_sh_attributions[m] = [[], [], []]\n",
        "    for i in range(len(sh_attributions_c[m][0])):\n",
        "        # Append base score\n",
        "        hf_sh_attributions[m][0].append(sh_attributions_c[m][0][i])\n",
        "        # Append attribution\n",
        "        hf_sh_attributions[m][1].append(sh_attributions_c[m][1][i])\n",
        "        # Append index\n",
        "        hf_sh_attributions[m][2].append(sh_attributions_c[m][2][i] + len(hvl))\n",
        "\n",
        "# Combine Halfvarson and Schirmer labels\n",
        "hvsl = torch.cat((hvl, sl))\n",
        "# Combine Halfvarson and Schirmer base scores\n",
        "hf_sh_base_scores = torch.cat((hf_base_scores, sh_base_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hZOcikebhvpZ"
      },
      "outputs": [],
      "source": [
        "pos_cf = 0.001\n",
        "neg_cf = 0.999\n",
        "\n",
        "top_hf_sh_abs_L_5_n_300, top_hf_sh_abs_L_5_n_300_stats, filtered_hf_sh_atts = filter_attributions_and_plot_hbars(hf_sh_attributions, n=30000, sort_by_positive_class_attribution=False, pos_cutoff = pos_cf, \\\n",
        "                                  neg_cutoff = neg_cf, lenlim = L, rarity_lim = rarity_l, absolute = False, title = \"Schirmer + Halfvarson (Per Sample STD)\", \\\n",
        "                                  data_labels=hvsl, filter=True, all_scores = hf_sh_base_scores, total_freqs = counts_dict, plot = False)\n",
        "\n",
        "# Set cutoff values for positive and negative class scores\n",
        "# Essentially disables this part of filtering, since we've already filtered once when generating hf_sh_attributions.\n",
        "pos_cf = 0.001\n",
        "neg_cf = 0.999\n",
        "\n",
        "# Process combined Halfvarson and Schirmer attributions\n",
        "top_hf_sh_abs_L_5_n_300, top_hf_sh_abs_L_5_n_300_stats, filtered_hf_sh_atts = filter_attributions_and_plot_hbars(\n",
        "    hf_sh_attributions,  # Combined Halfvarson and Schirmer attributions\n",
        "    n=30000,  # Number of top microbes to analyze (everything)\n",
        "    sort_by_positive_class_attribution=False,  # Sort by overall attribution, not just positive class\n",
        "    pos_cutoff=pos_cf,  # Cutoff for positive class scores (0.1% percentile)\n",
        "    neg_cutoff=neg_cf,  # Cutoff for negative class scores (99.9% percentile)\n",
        "    lenlim=L,  # Minimum number of attributions required (defined earlier)\n",
        "    rarity_lim=rarity_l,  # Minimum frequency of occurrence (defined earlier)\n",
        "    absolute=False,  # Use signed attributions, not absolute values\n",
        "    title=\"Schirmer + Halfvarson (Per Sample STD)\",\n",
        "    data_labels=hvsl,  # Combined Halfvarson and Schirmer labels\n",
        "    filter=True,  # Apply filtering based on scores and rarity\n",
        "    all_scores=hf_sh_base_scores,  # Combined base scores\n",
        "    total_freqs=counts_dict,  # Dictionary of total frequencies for each microbe\n",
        "    plot=False  # Don't generate a plot\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nFbKDbSq-Cpn"
      },
      "outputs": [],
      "source": [
        "def report_overlap(top_IBD_abs, top_half_abs, top_sch_abs):\n",
        "    \"\"\"\n",
        "    Reports the overlap between the top IBD, Halfvarson, and Schirmer microbes.\n",
        "\n",
        "    Args:\n",
        "    top_IBD_abs (list): List of top microbes from IBD dataset.\n",
        "    top_half_abs (list): List of top microbes from Halfvarson dataset.\n",
        "    top_sch_abs (list): List of top microbes from Schirmer dataset.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - intersections (list): List of overlap counts between datasets.\n",
        "        - overlap_lists (list): List of overlapping microbes between datasets.\n",
        "    \"\"\"\n",
        "    names = [\"IBD\", \"HF \", \"SH \"]\n",
        "    string = '     IBD HF  SH\\n'\n",
        "    intersections = []\n",
        "    overlap_lists = []\n",
        "    for x, name in zip([top_IBD_abs, top_half_abs, top_sch_abs], names):\n",
        "        row = []\n",
        "        string = string + name + \": \"\n",
        "        for y in [top_IBD_abs, top_half_abs, top_sch_abs]:\n",
        "            num_same = sum([1 if t in y else 0 for t in x])\n",
        "            overlap = [t for t in x if t in y and x != y]\n",
        "            string = string + str(num_same) + (\"  \" if len(str(num_same)) > 1 else \"   \")\n",
        "            row.append(num_same)\n",
        "            overlap_lists.append(overlap)\n",
        "        string = string + \"\\n\"\n",
        "        intersections.append(row)\n",
        "    print(string)\n",
        "    return intersections, overlap_lists\n",
        "\n",
        "def pick_entry(m, att_stats):\n",
        "    \"\"\"\n",
        "    Finds and returns the attribution statistics for a given microbe.\n",
        "\n",
        "    Args:\n",
        "    m (int): Microbe ID to search for.\n",
        "    att_stats (list): List of attribution statistics for all microbes.\n",
        "\n",
        "    Returns:\n",
        "    list or int: Attribution statistics for the microbe if found, -1 otherwise.\n",
        "    \"\"\"\n",
        "    for a in att_stats:\n",
        "        if a[0] == m:\n",
        "            return a\n",
        "    return -1\n",
        "\n",
        "#  k, len(attribution_dict[k][1]), sum(attribution_dict[k][1]), np.std(attribution_dict[k][1])\n",
        "\n",
        "def report_attributions(microbes, attribution_stats, dataset_names):\n",
        "    \"\"\"\n",
        "    Generates a report of attribution statistics for given microbes across multiple datasets.\n",
        "\n",
        "    Args:\n",
        "    microbes (list): List of microbe IDs to report on.\n",
        "    attribution_stats (list): List of attribution statistics for each dataset.\n",
        "    dataset_names (list): Names of the datasets.\n",
        "\n",
        "    Returns:\n",
        "    list: Sorted list of attribution reports for each microbe across all datasets.\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    for m in microbes:\n",
        "        microbe_result = [m]\n",
        "        for att, n in zip(attribution_stats, dataset_names):\n",
        "            microbe_stats = pick_entry(m, att)\n",
        "            if type(microbe_stats) == list:\n",
        "                n_averaged = microbe_stats[1]\n",
        "                avg_at = microbe_stats[2] / n_averaged\n",
        "                std = microbe_stats[3] / (n_averaged ** 0.5)\n",
        "                pos_in_orig = microbe_stats[4]\n",
        "                pads = 6 - len(str(n_averaged)) - len(str(pos_in_orig))\n",
        "                padding = ' '.join('' for _ in range(pads))\n",
        "                microbe_result.append([n, \"{:.5f}\".format(avg_at), \"{:.5f}\".format(std), str(n_averaged), str(pos_in_orig) + padding, avg_at])\n",
        "            else:\n",
        "                microbe_result.append([n, \"missing\", \"missing\", \"0\", \"---\", 0])\n",
        "        output.append(microbe_result)\n",
        "    output = sorted(output, reverse=True, key=lambda x : x[1][-1])\n",
        "    for mr in output:\n",
        "        for t in mr:\n",
        "            if type(t) == list and type(t[-1]) != str:\n",
        "                del t[-1]\n",
        "    return output\n",
        "\n",
        "def check_att_match(att_stats, microbes, cutoff):\n",
        "    \"\"\"\n",
        "    Checks which microbes have an average attribution above a given cutoff.\n",
        "\n",
        "    Args:\n",
        "    att_stats (list): Attribution statistics for all microbes.\n",
        "    microbes (list): List of microbe IDs to check.\n",
        "    cutoff (float): Minimum average attribution value.\n",
        "\n",
        "    Returns:\n",
        "    list: Microbes that pass the cutoff criterion.\n",
        "    \"\"\"\n",
        "    passed_microbes = []\n",
        "    for m in microbes:\n",
        "        microbe_stats = pick_entry(m, att_stats)\n",
        "        if type(microbe_stats) == list:\n",
        "            n_averaged = microbe_stats[1]\n",
        "            avg_at = microbe_stats[2] / n_averaged\n",
        "            if avg_at > cutoff:\n",
        "                passed_microbes.append(m)\n",
        "    return passed_microbes\n",
        "\n",
        "def check_passes_min_atts(all_att_stats, microbes, minimum):\n",
        "    \"\"\"\n",
        "    Checks which microbes have an average attribution above a minimum value across all datasets.\n",
        "\n",
        "    Args:\n",
        "    all_att_stats (list): List of attribution statistics for each dataset.\n",
        "    microbes (list): List of microbe IDs to check.\n",
        "    minimum (float): Minimum average attribution value.\n",
        "\n",
        "    Returns:\n",
        "    list: Microbes that pass the minimum criterion across all datasets.\n",
        "    \"\"\"\n",
        "    passed_microbes = []\n",
        "    for m in microbes:\n",
        "        passes_all_datasets = True\n",
        "        for att_stats in all_att_stats:\n",
        "            microbe_stats = pick_entry(m, att_stats)\n",
        "            if type(microbe_stats) == list:\n",
        "                n_averaged = microbe_stats[1]\n",
        "                avg_at = microbe_stats[2] / n_averaged\n",
        "                if avg_at < minimum:\n",
        "                    passes_all_datasets = False\n",
        "        if passes_all_datasets:\n",
        "            passed_microbes.append(m)\n",
        "    return passed_microbes\n",
        "\n",
        "\n",
        "def check_same_atts_sign(all_att_stats, microbes):\n",
        "    \"\"\"\n",
        "    Checks which microbes have the same attribution sign across all datasets.\n",
        "\n",
        "    Args:\n",
        "    all_att_stats (list): List of attribution statistics for each dataset.\n",
        "    microbes (list): List of microbe IDs to check.\n",
        "\n",
        "    Returns:\n",
        "    list: Microbes that have consistent attribution signs across all datasets.\n",
        "    \"\"\"\n",
        "    passed_microbes = []\n",
        "    for m in microbes:\n",
        "        att_list = []\n",
        "        for att_stats in all_att_stats:\n",
        "            microbe_stats = pick_entry(m, att_stats)\n",
        "            if type(microbe_stats) == list:\n",
        "                n_averaged = microbe_stats[1]\n",
        "                avg_at = microbe_stats[2] / n_averaged\n",
        "                att_list.append(avg_at < 0)\n",
        "        passes_all_datasets = (len(att_list) == len(all_att_stats))\n",
        "        current_sign = att_list[0]\n",
        "        for s in att_list[1:]:\n",
        "            if s != current_sign:\n",
        "                passes_all_datasets = False\n",
        "        if passes_all_datasets:\n",
        "            passed_microbes.append(m)\n",
        "    return passed_microbes\n",
        "\n",
        "\n",
        "def get_combined_microbes_atts(m, att_dicts):\n",
        "    \"\"\"\n",
        "    Retrieves all attributions for a given microbe across multiple attribution dictionaries.\n",
        "\n",
        "    Args:\n",
        "    m (int): Microbe ID to retrieve attributions for.\n",
        "    att_dicts (list): List of attribution dictionaries from different datasets.\n",
        "\n",
        "    Returns:\n",
        "    list: Combined list of attributions for the microbe across all datasets.\n",
        "    \"\"\"\n",
        "    atts = []\n",
        "    for att_dict in att_dicts:\n",
        "        if m in att_dict:\n",
        "            for a in att_dict[m][1]:\n",
        "                atts.append(a)\n",
        "    return atts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjSWouL-hKp9",
        "outputId": "bbae7f21-bdd4-47d5-95f0-4e9d90188f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     IBD HF  SH\n",
            "IBD: 2408  645  405  \n",
            "HF : 645  1829  204  \n",
            "SH : 405  204  550  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "intersections, overlaps = report_overlap(top_ibd_abs_L_5_n_300, top_half_abs_L_5_n_300, top_sh_abs_L_5_n_300)\n",
        "\n",
        "ibd_microbes = pd.DataFrame(list(ibd_attributions.keys()))\n",
        "hf_microbes = pd.DataFrame(list(hf_attributions.keys()))\n",
        "sh_microbes = pd.DataFrame(list(sh_attributions.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5xv2LRwVqmMC"
      },
      "outputs": [],
      "source": [
        "# Check if microbes pass the minimum attribution threshold\n",
        "\n",
        "top_half_pass_min_att = check_passes_min_atts([top_ibd_abs_L_5_n_300_stats, top_half_abs_L_5_n_300_stats, top_sh_abs_L_5_n_300_stats], top_half_abs_L_5_n_300, 0.0001)\n",
        "top_sch_pass_min_att = check_passes_min_atts([top_ibd_abs_L_5_n_300_stats, top_half_abs_L_5_n_300_stats, top_sh_abs_L_5_n_300_stats], top_sh_abs_L_5_n_300, 0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UC6XRiW3qLbQ"
      },
      "outputs": [],
      "source": [
        "# Check if microbes have the same attribution sign across all datasets\n",
        "\n",
        "top_half_sh_same_sign = check_same_atts_sign([top_ibd_abs_L_5_n_300_stats, top_hf_sh_abs_L_5_n_300_stats], top_hf_sh_abs_L_5_n_300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0DBFpZFkrXr-"
      },
      "outputs": [],
      "source": [
        "# Combine attributions for microbes that pass the above criteria\n",
        "combined_stats = []\n",
        "\n",
        "for m in top_half_sh_same_sign:\n",
        "    combined_atts = get_combined_microbes_atts(m, [filtered_hf_sh_atts, filtered_ibd_atts])\n",
        "    n = len(combined_atts)\n",
        "    mean_att = sum(combined_atts) / n\n",
        "    mean_std = torch.std(torch.tensor(combined_atts)).item() / n ** 0.5\n",
        "    combined_stats.append([m, n, mean_att, mean_std, \"Null\"])\n",
        "\n",
        "# Sort combined stats\n",
        "combined_stats = sorted(combined_stats, reverse = True, key=lambda x : x[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OvE6SXKgy573"
      },
      "outputs": [],
      "source": [
        "# Find top and bottom 10 microbes\n",
        "top_10_microbes = [stats[0] for stats in combined_stats[:10]]\n",
        "bottom_10_microbes = [stats[0] for stats in combined_stats[-10:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGV2WdBZit1h",
        "outputId": "5c09859f-a1b8-45ee-a43b-aa9c567213c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([2602, 1054, 5969, 2139, 2721, 1988, 506, 1116, 4202, 1555],\n",
              " [138, 99, 1013, 1074, 1711, 4830, 1050, 1785, 2710, 647])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_10_microbes, bottom_10_microbes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-UjfGUteTAei"
      },
      "outputs": [],
      "source": [
        "top_half_pass_min_att_pass_IBD_check = check_att_match(top_ibd_abs_L_5_n_300_stats, top_half_pass_min_att, 0.00098)\n",
        "top_sch_pass_min_att_pass_IBD_check = check_att_match(top_ibd_abs_L_5_n_300_stats, top_sch_pass_min_att, 0.00101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrGn5Av36U7x",
        "outputId": "df7a91c0-c169-47de-b918-605ed022b576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     IBD HF  SH\n",
            "IBD: 2408  645  405  \n",
            "HF : 645  1829  204  \n",
            "SH : 405  204  550  \n",
            "\n",
            "IBD / Halfvarson Overlap      =  [1054, 5620, 2602, 2721, 4626, 5690, 10722, 1205, 2139, 4202, 4768, 852, 4029, 1392, 1988, 1576, 1498, 1555, 2000, 891, 6116, 2074, 3451, 1510, 8077, 1044, 5267, 1133, 5752, 2018, 678, 1618, 2672, 688, 1534, 657, 1970, 2161, 1541, 746, 3407, 2623, 446, 5478, 1249, 1192, 2173, 2650, 2481, 693, 1729, 1540, 1958, 11627, 7271, 12357, 537, 2040, 979, 531, 965, 3866, 1307, 2149, 357, 2336, 5252, 510, 1775, 1037, 1219, 1123, 2010, 6042, 3188, 535, 794, 939, 3497, 1095, 1092, 1710, 1466, 3142, 2528, 2483, 2864, 937, 4389, 2687, 1138, 4664, 5393, 1030, 940, 931, 1232, 1289, 399, 2884, 1159, 3192, 1461, 466, 1301, 734, 1881, 1917, 1611, 630, 3097, 3987, 1927, 1554, 2046, 1571, 557, 964, 1965, 665, 379, 1367, 1587, 10260, 5776, 1717, 1164, 823, 1169, 3511, 1769, 715, 800, 959, 1002, 1080, 6204, 2144, 1446, 1595, 1084, 2093, 12757, 3099, 1366, 1034, 5278, 1149, 1722, 443, 1625, 2134, 348, 4196, 3936, 2302, 850, 1345, 661, 1420, 453, 3544, 4590, 1321, 893, 501, 1475, 4973, 1662, 1187, 2006, 465, 911, 2431, 1101, 764, 1150, 2143, 2476, 2802, 1253, 325, 387, 915, 1456, 973, 854, 1244, 1281, 3490, 2136, 2148, 1335, 862, 223, 851, 4065, 215, 3572, 2954, 1830, 1964, 1839, 918, 1055, 742, 349, 1108, 2087, 1473, 1089, 1380, 2237, 1638, 1533, 258, 306, 718, 355, 245, 3185, 1413, 583, 728, 1280, 1901, 1928, 763, 797, 369, 1607, 156, 1603, 1585, 2879, 1062, 487, 1412, 322, 1119, 1071, 329, 448, 669, 401, 2194, 638, 2443, 1494, 2953, 871, 3150, 2033, 2758, 1655, 1615, 1190, 3206, 1605, 641, 1049, 610, 1421, 1019, 1720, 3441, 482, 977, 1411, 951, 336, 2849, 396, 464, 2115, 2357, 285, 600, 5211, 799, 1308, 1300, 958, 1802, 1178, 4505, 1260, 2786, 1903, 2369, 490, 1777, 586, 573, 4159, 237, 251, 1748, 169, 1182, 710, 635, 365, 1016, 985, 2578, 434, 483, 11535, 3656, 1892, 560, 1007, 1408, 847, 572, 900, 1148, 1078, 1552, 2080, 722, 2155, 1741, 5545, 3315, 568, 2229, 2444, 1523, 227, 739, 541, 4716, 217, 3456, 1120, 3640, 1529, 538, 2609, 652, 275, 458, 1645, 817, 650, 3491, 7894, 4800, 1052, 1714, 1357, 184, 1750, 2764, 1327, 1223, 1949, 1406, 2515, 1429, 2484, 1160, 1183, 2511, 1950, 196, 545, 926, 906, 1480, 199, 1228, 119, 407, 1870, 967, 1012, 1258, 351, 1270, 1490, 3596, 707, 274, 2467, 1356, 1165, 110, 241, 4699, 609, 175, 323, 489, 122, 2004, 1337, 440, 887, 1474, 2896, 2499, 1053, 1112, 1287, 2035, 2123, 2586, 551, 131, 1039, 696, 129, 1047, 2356, 853, 335, 171, 845, 316, 103, 778, 2217, 1196, 2028, 143, 1817, 534, 1042, 2400, 8579, 137, 1698, 1543, 2600, 442, 721, 312, 2268, 100, 626, 976, 927, 1008, 111, 2041, 2903, 1379, 1689, 1098, 2097, 1256, 1568, 2215, 950, 858, 1715, 1616, 1001, 1604, 125, 1455, 2624, 519, 946, 1131, 117, 997, 536, 2191, 3082, 1842, 1885, 1061, 646, 645, 1065, 339, 228, 1697, 1360, 726, 1778, 1862, 1353, 1242, 252, 498, 998, 1828, 158, 264, 1626, 846, 484, 180, 1277, 503, 509, 1758, 210, 130, 1990, 2384, 269, 296, 1248, 1100, 108, 381, 982, 759, 697, 1562, 1801, 2702, 283, 450, 317, 1602, 493, 1826, 762, 1759, 540, 1383, 293, 706, 2288, 292, 1711, 955, 1066, 1156, 1867, 1426, 191, 1315, 1437, 419, 63, 984, 1849, 934, 152, 1703, 277, 221, 179, 1310, 1520, 1365, 364, 2183, 816, 2418, 1676, 605, 2130, 109, 619, 426, 432, 411, 943, 193, 1114, 1818, 163, 1746, 141, 1675, 1339, 1752, 1318, 879, 181, 533, 530, 1014, 2245, 340, 216, 1955, 372, 677, 1444, 1255, 1397, 1221, 1141, 1594, 582, 526, 126, 892, 9, 1079, 55, 1045, 1200, 102, 1051, 1229, 380, 2869, 3194, 2051, 589, 1500, 58, 3214, 1241, 840, 162, 1021, 1074, 4830, 1013, 1288, 400, 1682, 197, 1029, 57, 268, 2052, 138, 2110, 1483, 127, 99, 105, 3386, 999, 1989, 2710, 647, 1050, 1785, 112, 460, 101]\n",
            "IBD / Schirmer Overlap        =  [2074, 3822, 1205, 1116, 814, 678, 598, 922, 353, 891, 357, 308, 743, 214, 245, 800, 1249, 1367, 259, 156, 2115, 571, 693, 1466, 517, 1095, 215, 318, 742, 443, 387, 723, 344, 401, 421, 333, 1475, 940, 501, 500, 369, 564, 1648, 322, 438, 609, 1169, 448, 219, 1366, 1283, 871, 363, 250, 453, 506, 337, 336, 1927, 1990, 165, 764, 665, 1149, 1062, 173, 739, 745, 258, 239, 351, 361, 763, 1662, 237, 850, 560, 915, 1008, 179, 584, 2155, 641, 583, 287, 412, 305, 223, 575, 169, 536, 464, 184, 217, 218, 573, 384, 490, 1689, 1251, 59, 175, 797, 836, 1615, 977, 918, 227, 1157, 1271, 241, 225, 495, 122, 396, 200, 311, 696, 2006, 320, 645, 1091, 86, 199, 323, 216, 442, 403, 847, 350, 420, 989, 1067, 1014, 276, 58, 180, 698, 1761, 317, 778, 129, 710, 1012, 817, 302, 958, 275, 285, 479, 274, 103, 483, 1500, 799, 137, 171, 859, 113, 131, 125, 445, 706, 75, 1112, 296, 298, 158, 887, 77, 168, 93, 110, 428, 90, 321, 1604, 273, 277, 55, 1368, 444, 80, 82, 1052, 130, 972, 136, 1523, 85, 0, 406, 551, 172, 1675, 143, 332, 228, 646, 210, 765, 87, 57, 100, 107, 283, 230, 405, 96, 457, 91, 585, 224, 191, 222, 164, 119, 507, 286, 252, 316, 582, 41, 111, 262, 268, 721, 257, 886, 98, 840, 605, 1065, 1131, 297, 193, 460, 367, 163, 61, 556, 293, 105, 373, 94, 1248, 1242, 36, 78, 44, 151, 117, 62, 188, 176, 48, 2, 345, 381, 108, 84, 67, 72, 31, 375, 83, 201, 272, 73, 11, 47, 364, 2052, 440, 619, 46, 64, 63, 70, 1110, 33, 40, 515, 659, 484, 106, 624, 717, 42, 49, 9, 95, 221, 468, 34, 455, 205, 16, 30, 138, 38, 32, 60, 18, 289, 54, 181, 6, 114, 290, 69, 432, 45, 372, 526, 89, 126, 50, 655, 822, 97, 267, 5, 1064, 39, 26, 212, 109, 23, 15, 51, 53, 2110, 24, 52, 71, 22, 21, 3, 147, 8, 35, 562, 174, 20, 102, 116, 88, 7, 28, 528, 19, 10, 65, 76, 341, 2030, 115, 331, 1050, 502, 43, 13, 327, 81, 25, 815, 37, 74, 29, 226, 68, 5957, 17, 120, 12, 681, 92, 187, 56, 4, 593, 642, 542, 99, 383, 79, 1136, 281, 459, 1, 66, 27, 134, 670, 118, 1742, 14, 198, 340, 153, 266, 470, 255, 404]\n",
            "Halfvarson / Schirmer Overlap =  [2074, 1551, 1205, 4803, 2690, 13597, 678, 1075, 2629, 891, 2796, 1572, 357, 10198, 245, 800, 1249, 1367, 1871, 156, 2115, 4981, 693, 1466, 1095, 215, 742, 443, 387, 2830, 401, 3727, 1475, 2766, 940, 501, 369, 322, 609, 1169, 448, 1366, 871, 12418, 453, 336, 1927, 5093, 1990, 764, 665, 1149, 1062, 739, 258, 351, 763, 1662, 237, 850, 560, 2527, 8733, 915, 1008, 179, 2155, 641, 583, 223, 169, 536, 464, 11174, 184, 3527, 217, 573, 490, 1689, 175, 797, 1615, 977, 918, 227, 4296, 241, 122, 396, 3431, 696, 2006, 2967, 645, 1581, 3580, 199, 323, 216, 1859, 442, 847, 855, 1014, 58, 180, 317, 778, 129, 710, 1012, 10687, 817, 958, 275, 285, 274, 103, 483, 1500, 799, 137, 171, 796, 131, 125, 706, 1112, 296, 158, 887, 2899, 110, 1604, 277, 55, 1052, 130, 1523, 10193, 1354, 551, 1675, 143, 228, 646, 210, 57, 100, 283, 10105, 653, 4414, 191, 119, 252, 316, 582, 111, 268, 721, 840, 605, 1065, 1131, 193, 460, 163, 293, 105, 1248, 1242, 117, 381, 108, 643, 364, 2052, 440, 619, 63, 713, 484, 9, 221, 913, 138, 181, 432, 372, 526, 126, 109, 1573, 2110, 102, 1279, 1050, 1646, 99, 2776, 340, 15022]\n",
            "All overlap                   =  [1205, 891, 2074, 678, 1249, 693, 357, 1095, 1466, 940, 1927, 665, 1367, 1169, 800, 1366, 1149, 443, 850, 453, 501, 1475, 1662, 2006, 764, 387, 915, 223, 215, 918, 742, 258, 245, 583, 763, 797, 369, 156, 1062, 322, 448, 401, 871, 1615, 641, 977, 336, 396, 464, 2115, 285, 799, 958, 490, 573, 237, 169, 710, 483, 560, 847, 2155, 1523, 227, 739, 217, 275, 817, 1052, 184, 199, 119, 1012, 351, 274, 110, 241, 609, 175, 323, 122, 440, 887, 1112, 551, 131, 696, 129, 171, 316, 103, 778, 143, 137, 442, 721, 100, 1008, 111, 1689, 1604, 125, 1131, 117, 536, 646, 645, 1065, 228, 1242, 252, 158, 484, 180, 210, 130, 1990, 296, 1248, 108, 381, 283, 317, 293, 706, 191, 63, 277, 221, 179, 364, 605, 109, 619, 432, 193, 163, 1675, 181, 1014, 340, 216, 372, 582, 526, 126, 9, 55, 102, 1500, 58, 840, 57, 268, 2052, 138, 2110, 99, 105, 1050, 460]\n"
          ]
        }
      ],
      "source": [
        "# Report some overlap statistics\n",
        "\n",
        "intersections, overlap_lists = report_overlap(top_ibd_abs_L_5_n_300, top_half_abs_L_5_n_300, top_sh_abs_L_5_n_300)\n",
        "ibd_hf_overlap = overlap_lists[3]\n",
        "ibd_sh_overlap = overlap_lists[6]\n",
        "hf_sh_overlap = overlap_lists[7]\n",
        "all_overlap = [x for x in ibd_hf_overlap if x in hf_sh_overlap]\n",
        "print(\"IBD / Halfvarson Overlap      = \", ibd_hf_overlap)\n",
        "print(\"IBD / Schirmer Overlap        = \", ibd_sh_overlap)\n",
        "print(\"Halfvarson / Schirmer Overlap = \", hf_sh_overlap)\n",
        "print(\"All overlap                   = \", all_overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zg3avr0rLfA",
        "outputId": "f154cdb0-9fcd-4c1f-a7f3-b8430653b122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Top Schirmer Microbes Validated on IBD Microbe Average Attributions\n",
            "                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \n",
            "2074\t['IBD', '0.00264', '0.00023', '6', '15  ']\t['Halfvarson', '0.00069', '0.00006', '29', '322']\t['Schirmer', '0.00597', '0.00070', '10', '2  ']\n",
            "506\t['IBD', '0.00235', '0.00050', '5', '32  ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00100', '0.00020', '17', '119']\n",
            "1205\t['IBD', '0.00235', '0.00030', '10', '33 ']\t['Halfvarson', '0.00093', '0.00010', '19', '215']\t['Schirmer', '0.00515', '0.00241', '5', '7   ']\n",
            "814\t['IBD', '0.00230', '0.00020', '16', '39 ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00315', '0.00069', '5', '27  ']\n",
            "678\t['IBD', '0.00201', '0.00021', '21', '59 ']\t['Halfvarson', '0.00053', '0.00007', '15', '405']\t['Schirmer', '0.00306', '0.00042', '5', '29  ']\n",
            "891\t['IBD', '0.00173', '0.00015', '16', '91 ']\t['Halfvarson', '0.00071', '0.00005', '13', '310']\t['Schirmer', '0.00261', '0.00025', '10', '38 ']\n",
            "357\t['IBD', '0.00163', '0.00010', '51', '112']\t['Halfvarson', '0.00021', '0.00006', '58', '627']\t['Schirmer', '0.00229', '0.00022', '6', '43  ']\n",
            "500\t['IBD', '0.00150', '0.00022', '9', '138 ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00143', '0.00037', '5', '97  ']\n",
            "1249\t['IBD', '0.00133', '0.00008', '10', '194']\t['Halfvarson', '0.00039', '0.00005', '55', '506']\t['Schirmer', '0.00213', '0.00019', '6', '54  ']\n",
            "1095\t['IBD', '0.00132', '0.00010', '6', '197 ']\t['Halfvarson', '0.00010', '0.00006', '18', '720']\t['Schirmer', '0.00179', '0.00022', '6', '69  ']\n",
            "693\t['IBD', '0.00132', '0.00009', '21', '198']\t['Halfvarson', '0.00034', '0.00005', '48', '541']\t['Schirmer', '0.00185', '0.00028', '6', '64  ']\n",
            "421\t['IBD', '0.00132', '0.00010', '46', '200']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00158', '0.00042', '5', '89  ']\n",
            "1283\t['IBD', '0.00130', '0.00017', '5', '211 ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00114', '0.00021', '6', '111 ']\n",
            "3822\t['IBD', '0.00128', '0.00013', '5', '218 ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00541', '0.00133', '5', '3   ']\n",
            "1116\t['IBD', '0.00122', '0.00014', '12', '238']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00415', '0.00095', '7', '13  ']\n",
            "308\t['IBD', '0.00116', '0.00006', '39', '255']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00226', '0.00023', '10', '47 ']\n",
            "723\t['IBD', '0.00116', '0.00011', '19', '259']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00165', '0.00025', '5', '81  ']\n",
            "259\t['IBD', '0.00107', '0.00005', '84', '300']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00200', '0.00028', '12', '59 ']\n",
            "344\t['IBD', '0.00107', '0.00016', '48', '302']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00163', '0.00077', '5', '82  ']\n",
            "353\t['IBD', '0.00106', '0.00007', '60', '308']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00262', '0.00035', '17', '37 ']\n",
            "\n",
            "\n",
            "\n",
            "Top Halfvarson Microbes Validated on IBD Microbe Average Attributions\n",
            "                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \n",
            "2602\t['IBD', '0.00428', '0.00032', '5', '0   ']\t['Halfvarson', '0.00155', '0.00011', '15', '67 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "4202\t['IBD', '0.00405', '0.00119', '5', '1   ']\t['Halfvarson', '0.00090', '0.00009', '16', '224']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1054\t['IBD', '0.00363', '0.00039', '8', '2   ']\t['Halfvarson', '0.00183', '0.00025', '7', '40  ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2139\t['IBD', '0.00340', '0.00030', '5', '3   ']\t['Halfvarson', '0.00092', '0.00010', '7', '219 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2721\t['IBD', '0.00328', '0.00047', '5', '6   ']\t['Halfvarson', '0.00152', '0.00016', '11', '72 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2074\t['IBD', '0.00264', '0.00023', '6', '15  ']\t['Halfvarson', '0.00069', '0.00006', '29', '322']\t['Schirmer', '0.00597', '0.00070', '10', '2  ']\n",
            "1392\t['IBD', '0.00240', '0.00033', '5', '30  ']\t['Halfvarson', '0.00084', '0.00014', '9', '249 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1205\t['IBD', '0.00235', '0.00030', '10', '33 ']\t['Halfvarson', '0.00093', '0.00010', '19', '215']\t['Schirmer', '0.00515', '0.00241', '5', '7   ']\n",
            "852\t['IBD', '0.00231', '0.00027', '19', '36 ']\t['Halfvarson', '0.00089', '0.00006', '51', '228']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1988\t['IBD', '0.00226', '0.00029', '10', '43 ']\t['Halfvarson', '0.00083', '0.00014', '7', '251 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "10722\t['IBD', '0.00222', '0.00042', '5', '44  ']\t['Halfvarson', '0.00094', '0.00009', '23', '208']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1498\t['IBD', '0.00217', '0.00020', '9', '47  ']\t['Halfvarson', '0.00073', '0.00009', '11', '288']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1576\t['IBD', '0.00212', '0.00014', '13', '48 ']\t['Halfvarson', '0.00074', '0.00008', '9', '280 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1555\t['IBD', '0.00211', '0.00019', '10', '49 ']\t['Halfvarson', '0.00073', '0.00016', '5', '298 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1510\t['IBD', '0.00206', '0.00033', '9', '53  ']\t['Halfvarson', '0.00063', '0.00010', '5', '350 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "5267\t['IBD', '0.00206', '0.00020', '6', '54  ']\t['Halfvarson', '0.00059', '0.00007', '21', '365']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2018\t['IBD', '0.00202', '0.00022', '11', '57 ']\t['Halfvarson', '0.00053', '0.00008', '11', '404']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "678\t['IBD', '0.00201', '0.00021', '21', '59 ']\t['Halfvarson', '0.00053', '0.00007', '15', '405']\t['Schirmer', '0.00306', '0.00042', '5', '29  ']\n",
            "1037\t['IBD', '0.00197', '0.00014', '16', '61 ']\t['Halfvarson', '0.00019', '0.00006', '9', '643 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2161\t['IBD', '0.00194', '0.00008', '5', '65  ']\t['Halfvarson', '0.00045', '0.00003', '8', '463 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1618\t['IBD', '0.00190', '0.00036', '5', '67  ']\t['Halfvarson', '0.00049', '0.00011', '12', '430']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "5478\t['IBD', '0.00190', '0.00020', '5', '68  ']\t['Halfvarson', '0.00041', '0.00011', '9', '492 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "657\t['IBD', '0.00189', '0.00012', '33', '69 ']\t['Halfvarson', '0.00046', '0.00010', '20', '457']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "688\t['IBD', '0.00182', '0.00010', '42', '75 ']\t['Halfvarson', '0.00047', '0.00008', '36', '440']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1970\t['IBD', '0.00179', '0.00015', '14', '79 ']\t['Halfvarson', '0.00045', '0.00014', '6', '461 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "446\t['IBD', '0.00176', '0.00009', '44', '86 ']\t['Halfvarson', '0.00041', '0.00023', '19', '491']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "5620\t['IBD', '0.00174', '0.00040', '5', '90  ']\t['Halfvarson', '0.00168', '0.00028', '7', '53  ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "891\t['IBD', '0.00173', '0.00015', '16', '91 ']\t['Halfvarson', '0.00071', '0.00005', '13', '310']\t['Schirmer', '0.00261', '0.00025', '10', '38 ']\n",
            "531\t['IBD', '0.00169', '0.00008', '48', '96 ']\t['Halfvarson', '0.00026', '0.00006', '26', '597']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "12357\t['IBD', '0.00169', '0.00010', '11', '97 ']\t['Halfvarson', '0.00028', '0.00006', '12', '585']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2173\t['IBD', '0.00168', '0.00014', '6', '99  ']\t['Halfvarson', '0.00037', '0.00007', '11', '519']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1044\t['IBD', '0.00165', '0.00014', '13', '105']\t['Halfvarson', '0.00059', '0.00006', '11', '364']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2623\t['IBD', '0.00165', '0.00009', '10', '106']\t['Halfvarson', '0.00041', '0.00005', '27', '490']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1534\t['IBD', '0.00165', '0.00015', '11', '108']\t['Halfvarson', '0.00047', '0.00007', '19', '450']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "357\t['IBD', '0.00163', '0.00010', '51', '112']\t['Halfvarson', '0.00021', '0.00006', '58', '627']\t['Schirmer', '0.00229', '0.00022', '6', '43  ']\n",
            "3188\t['IBD', '0.00157', '0.00017', '9', '125 ']\t['Halfvarson', '0.00015', '0.00010', '5', '680 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2000\t['IBD', '0.00155', '0.00010', '13', '126']\t['Halfvarson', '0.00072', '0.00005', '30', '300']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "746\t['IBD', '0.00153', '0.00016', '12', '134']\t['Halfvarson', '0.00042', '0.00011', '17', '487']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "11627\t['IBD', '0.00146', '0.00021', '5', '150 ']\t['Halfvarson', '0.00030', '0.00008', '9', '573 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1192\t['IBD', '0.00145', '0.00019', '9', '152 ']\t['Halfvarson', '0.00038', '0.00003', '104', '513']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2149\t['IBD', '0.00144', '0.00021', '7', '158 ']\t['Halfvarson', '0.00022', '0.00016', '7', '620 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1541\t['IBD', '0.00138', '0.00016', '5', '170 ']\t['Halfvarson', '0.00042', '0.00006', '23', '485']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "965\t['IBD', '0.00137', '0.00015', '10', '175']\t['Halfvarson', '0.00024', '0.00004', '66', '605']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2672\t['IBD', '0.00136', '0.00011', '9', '176 ']\t['Halfvarson', '0.00048', '0.00006', '17', '436']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "537\t['IBD', '0.00135', '0.00008', '34', '180']\t['Halfvarson', '0.00027', '0.00005', '36', '589']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "510\t['IBD', '0.00134', '0.00007', '30', '184']\t['Halfvarson', '0.00020', '0.00005', '26', '636']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "4029\t['IBD', '0.00134', '0.00018', '5', '186 ']\t['Halfvarson', '0.00086', '0.00020', '13', '240']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1249\t['IBD', '0.00133', '0.00008', '10', '194']\t['Halfvarson', '0.00039', '0.00005', '55', '506']\t['Schirmer', '0.00213', '0.00019', '6', '54  ']\n",
            "1095\t['IBD', '0.00132', '0.00010', '6', '197 ']\t['Halfvarson', '0.00010', '0.00006', '18', '720']\t['Schirmer', '0.00179', '0.00022', '6', '69  ']\n",
            "693\t['IBD', '0.00132', '0.00009', '21', '198']\t['Halfvarson', '0.00034', '0.00005', '48', '541']\t['Schirmer', '0.00185', '0.00028', '6', '64  ']\n",
            "2481\t['IBD', '0.00132', '0.00013', '7', '201 ']\t['Halfvarson', '0.00034', '0.00005', '16', '535']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1133\t['IBD', '0.00131', '0.00017', '6', '205 ']\t['Halfvarson', '0.00059', '0.00019', '11', '366']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1729\t['IBD', '0.00131', '0.00008', '23', '208']\t['Halfvarson', '0.00032', '0.00005', '23', '553']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "979\t['IBD', '0.00129', '0.00010', '23', '216']\t['Halfvarson', '0.00027', '0.00004', '40', '595']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "6116\t['IBD', '0.00127', '0.00020', '5', '221 ']\t['Halfvarson', '0.00069', '0.00018', '6', '320 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2650\t['IBD', '0.00126', '0.00013', '8', '223 ']\t['Halfvarson', '0.00035', '0.00014', '5', '532 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "3451\t['IBD', '0.00124', '0.00021', '5', '227 ']\t['Halfvarson', '0.00063', '0.00006', '20', '349']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "5752\t['IBD', '0.00124', '0.00015', '5', '229 ']\t['Halfvarson', '0.00058', '0.00010', '7', '368 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "4768\t['IBD', '0.00119', '0.00014', '6', '247 ']\t['Halfvarson', '0.00090', '0.00009', '6', '225 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "794\t['IBD', '0.00115', '0.00011', '26', '262']\t['Halfvarson', '0.00011', '0.00005', '37', '708']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "6042\t['IBD', '0.00115', '0.00014', '6', '266 ']\t['Halfvarson', '0.00015', '0.00004', '20', '679']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "939\t['IBD', '0.00114', '0.00014', '19', '268']\t['Halfvarson', '0.00011', '0.00006', '23', '710']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "535\t['IBD', '0.00114', '0.00008', '29', '269']\t['Halfvarson', '0.00012', '0.00009', '15', '696']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2040\t['IBD', '0.00113', '0.00009', '8', '272 ']\t['Halfvarson', '0.00027', '0.00005', '10', '593']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "3866\t['IBD', '0.00107', '0.00015', '5', '299 ']\t['Halfvarson', '0.00023', '0.00006', '14', '614']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1958\t['IBD', '0.00102', '0.00005', '13', '331']\t['Halfvarson', '0.00031', '0.00014', '5', '566 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1123\t['IBD', '0.00102', '0.00017', '13', '334']\t['Halfvarson', '0.00018', '0.00007', '13', '656']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "3407\t['IBD', '0.00101', '0.00013', '7', '339 ']\t['Halfvarson', '0.00041', '0.00014', '5', '488 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2336\t['IBD', '0.00100', '0.00004', '5', '342 ']\t['Halfvarson', '0.00021', '0.00003', '176', '630']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "4626\t['IBD', '0.00099', '0.00014', '7', '349 ']\t['Halfvarson', '0.00114', '0.00011', '6', '147 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1219\t['IBD', '0.00099', '0.00008', '20', '351']\t['Halfvarson', '0.00019', '0.00004', '19', '652']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "\n",
            "\n",
            "\n",
            "Top Combined Microbe Average Attributions\n",
            "                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \n",
            "2602\t['IBD', '0.00428', '0.00032', '5', '0   ']\t['Halfvarson', '0.00155', '0.00011', '15', '67 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "4202\t['IBD', '0.00405', '0.00119', '5', '1   ']\t['Halfvarson', '0.00090', '0.00009', '16', '224']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1054\t['IBD', '0.00363', '0.00039', '8', '2   ']\t['Halfvarson', '0.00183', '0.00025', '7', '40  ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2139\t['IBD', '0.00340', '0.00030', '5', '3   ']\t['Halfvarson', '0.00092', '0.00010', '7', '219 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "2721\t['IBD', '0.00328', '0.00047', '5', '6   ']\t['Halfvarson', '0.00152', '0.00016', '11', '72 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "5969\t['IBD', '0.00261', '0.00013', '5', '17  ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "506\t['IBD', '0.00235', '0.00050', '5', '32  ']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00100', '0.00020', '17', '119']\n",
            "1988\t['IBD', '0.00226', '0.00029', '10', '43 ']\t['Halfvarson', '0.00083', '0.00014', '7', '251 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1555\t['IBD', '0.00211', '0.00019', '10', '49 ']\t['Halfvarson', '0.00073', '0.00016', '5', '298 ']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1116\t['IBD', '0.00122', '0.00014', '12', '238']\t['Halfvarson', 'missing', 'missing', '0', '---']\t['Schirmer', '0.00415', '0.00095', '7', '13  ']\n",
            "\n",
            "\n",
            "\n",
            "Bottom Combined Microbe Average Attributions\n",
            "                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \n",
            "2710\t['IBD', '-0.00057', '0.00013', '6', '1755']\t['Halfvarson', '-0.00334', '0.00044', '20', '1815']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "138\t['IBD', '-0.00092', '0.00005', '68', '2035']\t['Halfvarson', '-0.00286', '0.00007', '323', '1802']\t['Schirmer', '-0.00227', '0.00011', '82', '424']\n",
            "1013\t['IBD', '-0.00119', '0.00008', '32', '2190']\t['Halfvarson', '-0.00262', '0.00015', '133', '1791']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1785\t['IBD', '-0.00129', '0.00018', '10', '2226']\t['Halfvarson', '-0.00359', '0.00027', '20', '1819']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1050\t['IBD', '-0.00147', '0.00022', '15', '2297']\t['Halfvarson', '-0.00358', '0.00060', '17', '1818']\t['Schirmer', '-0.00320', '0.00018', '5', '491 ']\n",
            "4830\t['IBD', '-0.00151', '0.00064', '5', '2310']\t['Halfvarson', '-0.00257', '0.00016', '76', '1789']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1074\t['IBD', '-0.00163', '0.00021', '12', '2350']\t['Halfvarson', '-0.00256', '0.00018', '72', '1788']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "99\t['IBD', '-0.00206', '0.00007', '129', '2394']\t['Halfvarson', '-0.00298', '0.00018', '61', '1807']\t['Schirmer', '-0.00393', '0.00047', '24', '519']\n",
            "647\t['IBD', '-0.00208', '0.00015', '26', '2396']\t['Halfvarson', '-0.00343', '0.00041', '11', '1817']\t['Schirmer', 'missing', 'missing', '0', '---']\n",
            "1711\t['IBD', '-0.00209', '0.00057', '6', '2398']\t['Halfvarson', '-0.00151', '0.00022', '10', '1649']\t['Schirmer', 'missing', 'missing', '0', '---']\n"
          ]
        }
      ],
      "source": [
        "# Now we take a look at what happens when we validate the top schirmer and halfvarson microbes on the IBD dataset\n",
        "\n",
        "print(\"\\n\\n\\nTop Schirmer Microbes Validated on IBD Microbe Average Attributions\")\n",
        "print(\"                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \")\n",
        "all_overlap_atts = report_attributions(top_sch_pass_min_att_pass_IBD_check, [top_ibd_abs_L_5_n_300_stats, top_half_abs_L_5_n_300_stats, top_sh_abs_L_5_n_300_stats], [\"IBD\", \"Halfvarson\", \"Schirmer\"])\n",
        "for x in all_overlap_atts:\n",
        "    print('\\t'.join([str(y) for y in x]))\n",
        "\n",
        "print(\"\\n\\n\\nTop Halfvarson Microbes Validated on IBD Microbe Average Attributions\")\n",
        "print(\"                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \")\n",
        "all_overlap_atts = report_attributions(top_half_pass_min_att_pass_IBD_check, [top_ibd_abs_L_5_n_300_stats, top_half_abs_L_5_n_300_stats, top_sh_abs_L_5_n_300_stats], [\"IBD\", \"Halfvarson\", \"Schirmer\"])\n",
        "for x in all_overlap_atts:\n",
        "    print('\\t'.join([str(y) for y in x]))\n",
        "\n",
        "# And also look at the statistics of the top and bottom combined attributions\n",
        "print(\"\\n\\n\\nTop Combined Microbe Average Attributions\")\n",
        "print(\"                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \")\n",
        "all_overlap_atts = report_attributions(top_10_microbes, [top_ibd_abs_L_5_n_300_stats, top_half_abs_L_5_n_300_stats, top_sh_abs_L_5_n_300_stats], [\"IBD\", \"Halfvarson\", \"Schirmer\"])\n",
        "for x in all_overlap_atts:\n",
        "    print('\\t'.join([str(y) for y in x]))\n",
        "\n",
        "print(\"\\n\\n\\nBottom Combined Microbe Average Attributions\")\n",
        "print(\"                 Attribution  STD      N     Rank                      Attribution  STD      N     Rank                      Attribution  STD      N     Rank   \")\n",
        "all_overlap_atts = report_attributions(bottom_10_microbes, [top_ibd_abs_L_5_n_300_stats, top_half_abs_L_5_n_300_stats, top_sh_abs_L_5_n_300_stats], [\"IBD\", \"Halfvarson\", \"Schirmer\"])\n",
        "for x in all_overlap_atts:\n",
        "    print('\\t'.join([str(y) for y in x]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cGUbw6vQN9Yd"
      },
      "outputs": [],
      "source": [
        "# Print FASTA sequences for top and bottom microbes\n",
        "fastas = []\n",
        "for l in open(\"/path/to/seqs_.07_embed.fasta\", \"r\").readlines():\n",
        "    if len(l) > 20:\n",
        "        fastas.append(l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55WZmtvSU7Uh",
        "outputId": "9e7ee9ab-ed40-47fc-ee71-3d5cec83f397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: 2602, FASTA: TACGTAGGTGGCGAGCGTTGTCCGGAATTACTGGGTGTAAAGGGTGCGTAGGCGGGGATGCAAGTCAGATGTGAAATCTATCGGCTTAACTGGTAAACTGCATTTGAAACTGCATTTCTTGAGTGGTGGAGAGGTAAGCG\n",
            "ID: 1054, FASTA: CACCGGCAGCTCAAGTGGTAGCTGTTTTTATTGGGCCTAAAGCGTTCGTAGCCGGTTTGATAAGTCTTTGGTGAAAGCTTGTAGCTTAACTATAAGAATTGCTGAAGATACTGTCAGACTTGAAGTCGGGAGAGGTTAGA\n",
            "ID: 5969, FASTA: TACGTAGGTGGCAAGCGTTGTCCGGATTTACTGGGTGTAAAGGGCGAGTAGGCGGGACGGAAAGTCAGTAGTGAAATACCGAGGCTTAACTTCGGGGCTGCTATTGAAACTTCTGTTCTTGAGTGATGGAGAGGCAGGCG\n",
            "ID: 2139, FASTA: TACGTAGGGGGCAAGCGTTATCCGGAATTACTGGGTGTAAAGGGTGCGTAGGCGGCCCGGCAAGTTTGATGTGAAACCCATAGGCTTAACCTGTGGCATGCATCAAAAACTACCGAGCTAGAGTGCAGGAGAGGAAAGCG\n",
            "ID: 2721, FASTA: TACGTAGGGAGCGAGCGTTGTCCGGATTTACTGGGTGTAAAGGGCGTGCAGCCGGGCTGGTAAGTCAGATGTGAAATCCGTGGGCTTAACCCACGAACTGCATTTGAAACTGCTGGTCTTGAGTACCGGAGAGGTTATCG\n",
            "ID: 1988, FASTA: TACGTAGGTGGCAAGCGTTGTCCGGAATTACTGGGTGTAAAGGGAGCGTAGGCGGGAGTGCAAGTTGAATGTGAAAACGATGGGCTCAACCCATCGTTGCGTTCAAAACTGCATTTCTTGAGTGAAGTAGAGGTAAGCGG\n",
            "ID: 506, FASTA: TACGTAGGGGGCAAGCGTTATCCGGATTCATTGGGCGTAAAGCGCTCGTAGGCGGTCTGTTAGGTCGGGAGTTAAATCCGGGGGCTCAACCCCCGTTCGCTCCCGATACCGGCAGACTTGAGTTTGGTAGGGGAAGGTGG\n",
            "ID: 1116, FASTA: TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCCCTTAAGTCAGCGGTGAAAGTCTGTGGCTCAACCATAGAATTGCCGTTGAAACTGGGAGGCTTGAGTATGTTTGAGGCAGGTG\n",
            "ID: 4202, FASTA: TACGTAGGTGGCAAGCGTTGTCCGGAATTACTGGGTGTAAAGGGAGCGTAGGCGGTCTTGCAAGTTGAATGTTTAAACTATCGGCTTAACTGGTAGTCGCGTTCAAAACTGCAGGACTTGAGTGAAGTAGAGGCAGGCGG\n",
            "ID: 1555, FASTA: TACGTAGGTTGCGAGCGTTGTCCGGATTTACTGGGTGTAAAGGGTGCGTAGGCGGGAACGCAAGTCAGATGTGAAAGACCACGGCTCAACCGTGGTACTGCATTTGAAACTGTGTTTCTTGAGTGCAGGAGAGGTAAGCG\n",
            "\n",
            "ID: 138, FASTA: TACGTAGGGGGCAAGCGTTATCCGGATTTACTGGGTGTAAAGGGAGCGTAGACGGCGAAGCAAGTCTGAAGTGAAAACCCAGGGCTCAACCCTGGGACTGCTTTGGAAACTGTTTTGCTAGAGTGTCGGAGAGGTAAGTG\n",
            "ID: 99, FASTA: TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGGTTGTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAATTGATACTGGCAGTCTTGAGTACAGTTGAGGTAGGCG\n",
            "ID: 1013, FASTA: TACGGAAGGTCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCCGGAGATTAAGCGTGTTGTGAAATGTAGACGCTCAACGTCTGCACTGCAGCGCGAACTGGTTTCCTTGAGTACGCACAAAGTGGGCG\n",
            "ID: 1074, FASTA: TACGGAAGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCGGGCTTTTAAGTCAGCGGTCAAATGCCACGGCTCAACCGTGGCCAGCCGTTGAAACTGTAAGCCTTGAGTCTGCACAGGGCACATGG\n",
            "ID: 1711, FASTA: TACGTAGGGAGCGAGCGTTGTCCGGAATTACTGGGTGTAAAGGGAGCGTAGGCGGGACGGCAAGTCAGATGTGAAATACATGGGCTCAACCCATGGGCTGCATTTGAAACTGCTGTTCTTGAGTGAAGTAGAGGTAAGCG\n",
            "ID: 4830, FASTA: TACGTAGGGGGCAAGCGTTATCCGGATTTACTGGGTGTAAAGGGAGCGCAGGCGGTACGGCAAGTCTGATGTGAAAGCCCGGGGCTCAACCCCGGGACTGCATTGGAAACTGTCGGACTAGAGTGTCGGAGGGGTAAGTG\n",
            "ID: 1050, FASTA: TACGTAGGTGGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGCGCGCGCAGGCGGCCGTGCAAGTCCATCTTAAAAGCGTGGGGCTTAACCCCATGAGGGGATGGAAACTGCAGGGCTGGAGTGTCGGAGGGGAAAGTGG\n",
            "ID: 1785, FASTA: TACGTAGGTGGCGAGCGTTGTCCGGATTTATTGGGCGTAAAGGGAACGCAGGCGGTCTTTTAAGTCTGATGTGAAAGCCTTCGGCTTAACCGAAGTAGTGCATTGGAAACTGGAAGACTTGAGTGCAGAAGAGGAGAGTG\n",
            "ID: 2710, FASTA: TACGGGGGATGCGAGCGTTATCCGGATTCATTGGGTTTAAAGGGTGCGTAGGCGGCCGAGTAAGTCAGCGGTGAAAGACCGGGGCTCAACCCTGGAAGTGCCGTTGATACTGTTTGGCTGGAATGATCCCGCCGCGGGAG\n",
            "ID: 647, FASTA: TACGGAAGGTTCGGGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCCGTTTGGTAAGCGTGTTGTGAAATGTAGGAGCTCAACTTCTAGATTGCAGCGCGAACTGTCAGACTTGAGTGCGCACAACGTAGGCG\n"
          ]
        }
      ],
      "source": [
        "# Print FASTA sequences for top 10 microbes\n",
        "for id in top_10_microbes:\n",
        "    print(\"ID: \" + str(id) + \", FASTA: \" + fastas[id][:-1])\n",
        "print()\n",
        "\n",
        "# Print FASTA sequences for bottom 10 microbes\n",
        "for id in bottom_10_microbes:\n",
        "    print(\"ID: \" + str(id) + \", FASTA: \" + fastas[id][:-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
